C:\Users\rasek\AppData\Local\Programs\Python\Python39\python.exe "A:/Research Assistant/MNIST D/main.py"
2021-05-28 14:14:44.578300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-05-28 14:14:44.578417: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
2021-05-28 14:14:46.372255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2021-05-28 14:14:46.372353: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-05-28 14:14:46.374543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-04NE6UJ
2021-05-28 14:14:46.374694: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-04NE6UJ
2021-05-28 14:14:46.375117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     
_________________________________________________________________
dropout (Dropout)            (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 7, 64)          0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 64)          36928     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 2, 2, 64)          36928     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 1, 1, 64)          36928     
_________________________________________________________________
dropout_2 (Dropout)          (None, 1, 1, 64)          0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 64)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense (Dense)                (None, 10)                650       
=================================================================
Total params: 167,178
Trainable params: 167,178
Non-trainable params: 0
_________________________________________________________________
2021-05-28 14:14:47.258971: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/15
422/422 [==============================] - 23s 54ms/step - loss: 0.6510 - accuracy: 0.7852 - val_loss: 0.1086 - val_accuracy: 0.9690
Epoch 2/15
422/422 [==============================] - 23s 54ms/step - loss: 0.1883 - accuracy: 0.9483 - val_loss: 0.0634 - val_accuracy: 0.9812
Epoch 3/15
422/422 [==============================] - 23s 55ms/step - loss: 0.1251 - accuracy: 0.9660 - val_loss: 0.0478 - val_accuracy: 0.9862
Epoch 4/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0950 - accuracy: 0.9754 - val_loss: 0.0418 - val_accuracy: 0.9898
Epoch 5/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0756 - accuracy: 0.9804 - val_loss: 0.0543 - val_accuracy: 0.9867
Epoch 6/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0649 - accuracy: 0.9837 - val_loss: 0.0339 - val_accuracy: 0.9903
Epoch 7/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0561 - accuracy: 0.9851 - val_loss: 0.0400 - val_accuracy: 0.9892
Epoch 8/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0501 - accuracy: 0.9873 - val_loss: 0.0451 - val_accuracy: 0.9890
Epoch 9/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0468 - accuracy: 0.9882 - val_loss: 0.0375 - val_accuracy: 0.9912
Epoch 10/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 0.0375 - val_accuracy: 0.9927
Epoch 11/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0372 - accuracy: 0.9904 - val_loss: 0.0430 - val_accuracy: 0.9897
Epoch 12/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0367 - accuracy: 0.9903 - val_loss: 0.0552 - val_accuracy: 0.9892
Epoch 13/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0339 - accuracy: 0.9906 - val_loss: 0.0524 - val_accuracy: 0.9907
Epoch 14/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0318 - val_accuracy: 0.9938
Epoch 15/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0280 - accuracy: 0.9925 - val_loss: 0.0332 - val_accuracy: 0.9930
Test loss: 0.027546728029847145
Test accuracy: 0.9926000237464905

Process finished with exit code 0

--------------------------------------------------------------------------------------------------------
model = keras.Sequential(
    [
        keras.Input(shape=input_shape),

        layers.Conv2D(32, kernel_size=(3, 3), activation="relu", padding='same'),
        #layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),


        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),


        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),


        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        #layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),

        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        #layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),

        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),

        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation="softmax"),
    ]
)


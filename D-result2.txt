C:\Users\rasek\AppData\Local\Programs\Python\Python39\python.exe "A:/Research Assistant/MNIST D/main.py"
2021-05-28 14:33:54.833754: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-05-28 14:33:54.833860: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
2021-05-28 14:33:56.630030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2021-05-28 14:33:56.630123: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-05-28 14:33:56.632265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-04NE6UJ
2021-05-28 14:33:56.632383: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-04NE6UJ
2021-05-28 14:33:56.632706: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 28, 28, 32)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     
_________________________________________________________________
dropout (Dropout)            (None, 14, 14, 64)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 7, 64)          0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 64)          36928     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 2, 2, 64)          36928     
_________________________________________________________________
dropout_2 (Dropout)          (None, 2, 2, 64)          0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 1, 1, 64)          36928     
_________________________________________________________________
dropout_3 (Dropout)          (None, 1, 1, 64)          0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 64)                0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense (Dense)                (None, 10)                650       
=================================================================
Total params: 167,178
Trainable params: 167,178
Non-trainable params: 0
_________________________________________________________________
2021-05-28 14:33:56.945678: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/15
422/422 [==============================] - 23s 54ms/step - loss: 0.4552 - accuracy: 0.8524 - val_loss: 0.0818 - val_accuracy: 0.9750
Epoch 2/15
422/422 [==============================] - 23s 55ms/step - loss: 0.1139 - accuracy: 0.9685 - val_loss: 0.0540 - val_accuracy: 0.9845
Epoch 3/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0786 - accuracy: 0.9786 - val_loss: 0.0420 - val_accuracy: 0.9888
Epoch 4/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0610 - accuracy: 0.9826 - val_loss: 0.0370 - val_accuracy: 0.9900
Epoch 5/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0450 - val_accuracy: 0.9872
Epoch 6/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0410 - accuracy: 0.9886 - val_loss: 0.0373 - val_accuracy: 0.9890
Epoch 7/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0355 - accuracy: 0.9899 - val_loss: 0.0334 - val_accuracy: 0.9905
Epoch 8/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0346 - accuracy: 0.9904 - val_loss: 0.0335 - val_accuracy: 0.9903
Epoch 9/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0300 - accuracy: 0.9919 - val_loss: 0.0336 - val_accuracy: 0.9910
Epoch 10/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0335 - val_accuracy: 0.9908
Epoch 11/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.0291 - val_accuracy: 0.9932
Epoch 12/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0341 - val_accuracy: 0.9902
Epoch 13/15
422/422 [==============================] - 23s 55ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0314 - val_accuracy: 0.9933
Epoch 14/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0302 - val_accuracy: 0.9937
Epoch 15/15
422/422 [==============================] - 23s 54ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0313 - val_accuracy: 0.9930
Test loss: 0.03238861262798309
Test accuracy: 0.9914000034332275

Process finished with exit code 0

------------------------------------------------------------------------------------------

model = keras.Sequential(
    [
        keras.Input(shape=input_shape),

        layers.Conv2D(32, kernel_size=(3, 3), activation="relu", padding='same'),
        #layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),


        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),


        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.05),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),


        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        #layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),

        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.1),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),

        layers.Conv2D(64, kernel_size=(3, 3), activation="relu", padding='same'),
        layers.Dropout(0.05),
        layers.MaxPooling2D(pool_size=(2, 2), padding='same'),

        layers.Flatten(),
        layers.Dropout(0.3),
        layers.Dense(num_classes, activation="softmax"),
    ]
)
